@article{jaksch2010near,
  title={Near-optimal regret bounds for reinforcement learning},
  author={Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={Apr},
  pages={1563--1600},
  year={2010}
}

@inproceedings{bartlett2009regal,
  title={REGAL: A regularization based algorithm for reinforcement learning in weakly communicating MDPs},
  author={Bartlett, Peter L and Tewari, Ambuj},
  booktitle={Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence},
  pages={35--42},
  year={2009},
  organization={AUAI Press}
}

@inproceedings{ng1999policy,
  title={Policy invariance under reward transformations: Theory and application to reward shaping},
  author={Ng, Andrew Y and Harada, Daishi and Russell, Stuart},
  booktitle={ICML},
  volume={99},
  pages={278--287},
  year={1999}
}

@article{wiewiora2003potential,
  title={Potential-based shaping and Q-value initialization are equivalent},
  author={Wiewiora, Eric},
  journal={Journal of Artificial Intelligence Research},
  volume={19},
  pages={205--208},
  year={2003}
}

@article{kober2013reinforcement,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1238--1274},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}

@book{clouse1996integrating,
  title={On integrating apprentice learning and reinforcement learning},
  author={Clouse, Jeffery Allen},
  year={1996},
  publisher={University of Massachusetts Amherst}
}
